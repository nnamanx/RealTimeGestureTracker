{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e33edcbf-3d16-4e64-92c6-01af097c7839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mediapipe opencv-python numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e44b1ed-a381-47a0-94e2-bf1f0f0d1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bfe7da-1a07-4409-a4d7-75863eb10dc4",
   "metadata": {},
   "source": [
    "<p>min_detection_confidence = 0.7</p>\n",
    "<ul>\n",
    "  <li>If confidence drops below <strong>0.5</strong>, MediaPipe will stop tracking that hand until it’s detected again.</li>\n",
    "  <li><span style=\"color:green;\">Higher values (e.g., 0.8)</span> → more accuracy, but the hand may “disappear” more often if detection isn’t strong.</li>\n",
    "  <li><span style=\"color:orange;\">Lower values (e.g., 0.3)</span> → more tolerant, but increases the chance of false positives or “ghost” hands.</li>\n",
    "</ul>\n",
    "\n",
    "<h2>multi_hand_landmarks</h2>\n",
    "<p>Contains all the hands it found. Since we only allow 1 hand, this will have <strong>0 or 1</strong>.</p>\n",
    "\n",
    "<h2>How MediaPipe Hand Landmarks Work</h2>\n",
    "<p>MediaPipe gives us 21 points per hand, each with:</p>\n",
    "<ul>\n",
    "  <li><code>x</code> = horizontal position (0 = left, 1 = right)</li>\n",
    "  <li><code>y</code> = vertical position (0 = top, 1 = bottom)</li>\n",
    "  <li><code>z</code> = depth (not important for this part)</li>\n",
    "</ul>\n",
    "\n",
    "<p>The points are numbered in a fixed order:</p>\n",
    "<table border=\"1\" cellpadding=\"5\" style=\"border-collapse:collapse;\">\n",
    "  <tr>\n",
    "    <th>Finger</th>\n",
    "    <th>Indices</th>\n",
    "    <th>Tip</th>\n",
    "  </tr>\n",
    "  <tr><td>Thumb</td><td>[1, 2, 3, 4]</td><td>4</td></tr>\n",
    "  <tr><td>Index</td><td>[5, 6, 7, 8]</td><td>8</td></tr>\n",
    "  <tr><td>Middle</td><td>[9, 10, 11, 12]</td><td>12</td></tr>\n",
    "  <tr><td>Ring</td><td>[13, 14, 15, 16]</td><td>16</td></tr>\n",
    "  <tr><td>Pinky</td><td>[17, 18, 19, 20]</td><td>20</td></tr>\n",
    "</table>\n",
    "\n",
    "<p><img src=\"img.ppm.png\" alt=\"MediaPipe Hand Landmarks\" style=\"max-width:100%;border:1px solid #ccc;border-radius:4px;\"></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7205369-5da6-4a41-a2a9-e5bb98f99fc0",
   "metadata": {},
   "source": [
    "<h1><i>Code</i></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "220ffe78-c50a-4679-b66b-eb57419b031a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755110093.120357  646763 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1755110093.137765  646953 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755110093.144709  646953 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "2025-08-13 22:34:53.331 python[72291:646763] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "W0000 00:00:1755110094.676286  646956 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesture History in Order:\n",
      "['No Hand', 'OK', 'No Hand', 'OK', 'No Hand', 'OK', 'No Hand', 'Thumbs Up', 'No Hand', 'Thumbs Up', 'No Hand', 'Thumbs Up', 'No Hand', 'Thumbs Up', 'No Hand', 'Thumbs Up', 'Fist', 'No Hand', 'Thumbs Up', 'No Hand', 'Thumbs Up', 'No Hand', 'Thumbs Up', 'No Hand', 'OK', 'Thumbs Up', 'Peace', 'No Hand', 'Thumbs Up', 'Fist', 'Thumbs Up', 'Fist', 'Thumbs Up', 'Fist', 'Thumbs Up', 'Fist', 'Thumbs Up', 'No Hand', 'Fist', 'Thumbs Up', 'No Hand', 'OK', 'No Hand', 'OK', 'No Hand', 'OK', 'No Hand', 'OK', 'No Hand', 'OK', 'No Hand', 'OK', 'No Hand', 'OK', 'No Hand', 'Thumbs Up', 'Peace', 'Thumbs Up', 'Fist', 'Thumbs Up', 'Fist', 'Thumbs Up', 'Fist', 'No Hand', 'Fist', 'Thumbs Up', 'No Hand', 'Peace', 'Thumbs Up', 'No Hand']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp #landmark detection\n",
    "import math\n",
    "import os # In order to turn off noisy log messages\n",
    "\n",
    "# Shows only important errors\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=1, # Detecting only 1 hand at a time\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.5 # For tracking the detected hand\n",
    ")\n",
    "\n",
    "# Opens webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# measures the distance between two points, like the thumb tip and index tip.\n",
    "# Pythagoras formula: √((x1−x2)² + (y1−y2)²)\n",
    "def distance(point1, point2):\n",
    "    return math.sqrt((point1.x - point2.x)**2 + (point1.y - point2.y)**2)\n",
    "\n",
    "# List to store gesture history\n",
    "gesture_history = [] \n",
    "prev_gesture = None # It is for storing the last gesture, so i don’t log the same thing repeatedly if i hold it still.\n",
    "\n",
    "# Put while to get manual stop instead time\n",
    "while True: \n",
    "    ret, frame = cap.read()  # takes 1 frame from the cam\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\") # if failed, the program stops\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)  # Flips the video horizontally so it feels like a mirror\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # OpenCV uses BGR (by default), but MediaPipe uses RGB. So this swaps \n",
    "    results = hands.process(frame_rgb)\n",
    "\n",
    "    gesture = \"No Hand\" # Default until one is detected\n",
    "\n",
    "    if results.multi_hand_landmarks: \n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Draws dots for the joints and lines connecting them\n",
    "            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS) \n",
    "            lm = hand_landmarks.landmark\n",
    "\n",
    "            # Each finger has numbered points\n",
    "            thumb_tip = lm[4]\n",
    "            index_tip = lm[8]\n",
    "            middle_tip = lm[12]\n",
    "            ring_tip = lm[16]\n",
    "            pinky_tip = lm[20]\n",
    "\n",
    "            \n",
    "            # These lines check if the tip is lower (y is bigger) than the joint below it\n",
    "            # Lower = finger folded down\n",
    "            # Higher = finger up\n",
    "            # thumb_up is a special case since the thumb bends differently\n",
    "            index_folded = index_tip.y > lm[6].y\n",
    "            middle_folded = middle_tip.y > lm[10].y\n",
    "            ring_folded = ring_tip.y > lm[14].y\n",
    "            pinky_folded = pinky_tip.y > lm[18].y\n",
    "            thumb_up = thumb_tip.y < lm[3].y\n",
    "            thumb_folded = thumb_tip.y > lm[3].y\n",
    "\n",
    "            # rules\n",
    "            if thumb_up and index_folded and middle_folded and ring_folded and pinky_folded:\n",
    "                gesture = \"Thumbs Up\"\n",
    "            elif not index_folded and not middle_folded and ring_folded and pinky_folded:\n",
    "                gesture = \"Peace\"\n",
    "            elif index_folded and middle_folded and ring_folded and pinky_folded and thumb_folded:\n",
    "                gesture = \"Fist\"\n",
    "            elif not index_folded and not middle_folded and not ring_folded and not pinky_folded and not thumb_up:\n",
    "                gesture = \"Open Hand\"\n",
    "            elif distance(thumb_tip, index_tip) < 0.05:\n",
    "                gesture = \"OK\"\n",
    "\n",
    "    # Record gesture if it is different from the previous one\n",
    "    if gesture != prev_gesture:\n",
    "        gesture_history.append(gesture)\n",
    "        prev_gesture = gesture\n",
    "\n",
    "    # Draws the name of the gesture on the top-left of the frame\n",
    "    cv2.putText(frame, f'Gesture: {gesture}', (10,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "    # display last 5 gestures\n",
    "    for i, g in enumerate(gesture_history[-5:]):\n",
    "        cv2.putText(frame, g, (10, 100 + i*30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,200,255), 2)\n",
    "\n",
    "    cv2.imshow(\"Hand Gesture Recognition\", frame) # Opens a separate window with the processed video\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # ESC to quit\n",
    "        break\n",
    "\n",
    "cap.release() # turns off the camera\n",
    "cv2.destroyAllWindows() # close windows\n",
    "hands.close() # release resources\n",
    "\n",
    "# Print full gesture history\n",
    "print(\"Gesture History in Order:\")\n",
    "print(gesture_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bf8736-0979-45c7-b4e6-7bc1da1ade74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
